{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZRuxIE8Ksxr9",
        "outputId": "33141922-9856-4409-9914-6977f85d5bec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas==2.2.2 in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas==2.2.2) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas==2.2.2) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas==2.2.2) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas==2.2.2) (2025.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.8.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.36.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas==2.2.2) (1.17.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.10.5)\n",
            "Collecting numpy==1.26.4\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m82.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "c930e3eeeeb94441b7ce5e0b5d137f86",
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting chromadb==1.0.20\n",
            "  Downloading chromadb-1.0.20-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.0.20) (1.3.0)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.0.20) (2.11.10)\n",
            "Collecting pybase64>=1.4.1 (from chromadb==1.0.20)\n",
            "  Downloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==1.0.20) (0.38.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.0.20) (1.26.4)\n",
            "Collecting posthog<6.0.0,>=2.4.0 (from chromadb==1.0.20)\n",
            "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.0.20) (4.15.0)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb==1.0.20)\n",
            "  Downloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.0.20) (1.37.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb==1.0.20)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.38.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.0.20) (1.37.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.0.20) (0.22.1)\n",
            "Collecting pypika>=0.48.9 (from chromadb==1.0.20)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.0.20) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.0.20) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb==1.0.20) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.0.20) (1.76.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb==1.0.20)\n",
            "  Downloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.0.20) (0.20.0)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb==1.0.20)\n",
            "  Downloading kubernetes-34.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.0.20) (8.5.0)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.0.20) (6.0.3)\n",
            "Collecting mmh3>=4.0.1 (from chromadb==1.0.20)\n",
            "  Downloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.0.20) (3.11.4)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.0.20) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.0.20) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.0.20) (4.25.1)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb==1.0.20) (25.0)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb==1.0.20) (1.2.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb==1.0.20) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb==1.0.20) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb==1.0.20) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb==1.0.20) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb==1.0.20) (0.16.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb==1.0.20) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb==1.0.20) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb==1.0.20) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb==1.0.20) (0.28.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb==1.0.20) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb==1.0.20) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb==1.0.20) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb==1.0.20) (1.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb==1.0.20) (2.32.4)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb==1.0.20) (2.0.0)\n",
            "Collecting urllib3<2.4.0,>=1.24.2 (from kubernetes>=28.1.0->chromadb==1.0.20)\n",
            "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb==1.0.20)\n",
            "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb==1.0.20)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb==1.0.20) (25.9.23)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb==1.0.20) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb==1.0.20) (1.13.3)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb==1.0.20) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==1.0.20) (1.71.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.38.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==1.0.20)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.38.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.38.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==1.0.20)\n",
            "  Downloading opentelemetry_proto-1.38.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb==1.0.20)\n",
            "  Downloading opentelemetry_sdk-1.38.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb==1.0.20)\n",
            "  Downloading opentelemetry_api-1.38.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.59b0 (from opentelemetry-sdk>=1.2.0->chromadb==1.0.20)\n",
            "  Downloading opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb==1.0.20)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb==1.0.20) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb==1.0.20) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb==1.0.20) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb==1.0.20) (0.4.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb==1.0.20) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb==1.0.20) (2.19.2)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers>=0.13.2->chromadb==1.0.20) (0.36.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb==1.0.20) (8.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb==1.0.20) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb==1.0.20)\n",
            "  Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==1.0.20) (1.2.1)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb==1.0.20)\n",
            "  Downloading uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb==1.0.20)\n",
            "  Downloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==1.0.20) (15.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==1.0.20) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==1.0.20) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==1.0.20) (4.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb==1.0.20) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb==1.0.20) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb==1.0.20) (1.2.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb==1.0.20) (3.23.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb==1.0.20) (0.1.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kubernetes>=28.1.0->chromadb==1.0.20) (3.4.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.27.0->chromadb==1.0.20) (1.3.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb==1.0.20)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb==1.0.20) (3.3.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb==1.0.20) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==1.0.20) (0.6.1)\n",
            "Downloading chromadb-1.0.20-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.8/19.8 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl (278 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-34.1.0-py2.py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.38.0-py3-none-any.whl (19 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.38.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.38.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_sdk-1.38.0-py3-none-any.whl (132 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.3/132.3 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.38.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.9/65.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.0/208.0 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
            "Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (517 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.7/517.7 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (4.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m95.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (456 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m456.8/456.8 kB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=08e80f9ea32e29774c79dd73472768a4df39e952f36f2d393e0feb27fc8f4589\n",
            "  Stored in directory: /root/.cache/pip/wheels/d5/3d/69/8d68d249cd3de2584f226e27fd431d6344f7d70fd856ebd01b\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, durationpy, uvloop, urllib3, pybase64, opentelemetry-proto, mmh3, humanfriendly, httptools, bcrypt, backoff, watchfiles, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, coloredlogs, posthog, opentelemetry-semantic-conventions, onnxruntime, opentelemetry-sdk, kubernetes, opentelemetry-exporter-otlp-proto-grpc, chromadb\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.5.0\n",
            "    Uninstalling urllib3-2.5.0:\n",
            "      Successfully uninstalled urllib3-2.5.0\n",
            "  Attempting uninstall: opentelemetry-proto\n",
            "    Found existing installation: opentelemetry-proto 1.37.0\n",
            "    Uninstalling opentelemetry-proto-1.37.0:\n",
            "      Successfully uninstalled opentelemetry-proto-1.37.0\n",
            "  Attempting uninstall: opentelemetry-exporter-otlp-proto-common\n",
            "    Found existing installation: opentelemetry-exporter-otlp-proto-common 1.37.0\n",
            "    Uninstalling opentelemetry-exporter-otlp-proto-common-1.37.0:\n",
            "      Successfully uninstalled opentelemetry-exporter-otlp-proto-common-1.37.0\n",
            "  Attempting uninstall: opentelemetry-api\n",
            "    Found existing installation: opentelemetry-api 1.37.0\n",
            "    Uninstalling opentelemetry-api-1.37.0:\n",
            "      Successfully uninstalled opentelemetry-api-1.37.0\n",
            "  Attempting uninstall: opentelemetry-semantic-conventions\n",
            "    Found existing installation: opentelemetry-semantic-conventions 0.58b0\n",
            "    Uninstalling opentelemetry-semantic-conventions-0.58b0:\n",
            "      Successfully uninstalled opentelemetry-semantic-conventions-0.58b0\n",
            "  Attempting uninstall: opentelemetry-sdk\n",
            "    Found existing installation: opentelemetry-sdk 1.37.0\n",
            "    Uninstalling opentelemetry-sdk-1.37.0:\n",
            "      Successfully uninstalled opentelemetry-sdk-1.37.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-adk 1.17.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.38.0 which is incompatible.\n",
            "google-adk 1.17.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-exporter-otlp-proto-common==1.37.0, but you have opentelemetry-exporter-otlp-proto-common 1.38.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-proto==1.37.0, but you have opentelemetry-proto 1.38.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-sdk~=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed backoff-2.2.1 bcrypt-5.0.0 chromadb-1.0.20 coloredlogs-15.0.1 durationpy-0.10 httptools-0.7.1 humanfriendly-10.0 kubernetes-34.1.0 mmh3-5.2.0 onnxruntime-1.23.2 opentelemetry-api-1.38.0 opentelemetry-exporter-otlp-proto-common-1.38.0 opentelemetry-exporter-otlp-proto-grpc-1.38.0 opentelemetry-proto-1.38.0 opentelemetry-sdk-1.38.0 opentelemetry-semantic-conventions-0.59b0 posthog-5.4.0 pybase64-1.4.2 pypika-0.48.9 urllib3-2.3.0 uvloop-0.22.1 watchfiles-1.1.1\n",
            "Collecting rank_bm25==0.2.2\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rank_bm25==0.2.2) (1.26.4)\n",
            "Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Installing collected packages: rank_bm25\n",
            "Successfully installed rank_bm25-0.2.2\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.2/56.2 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.11.0)\n",
            "Requirement already satisfied: transformers>=4.44 in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (0.17.1)\n",
            "Requirement already satisfied: torch<3,>=2.3 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.8.0+cu126)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate) (6.0.3)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.36.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers>=4.44) (3.20.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.44) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers>=4.44) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.44) (0.22.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.44) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.4.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.44) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.44) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.44) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.44) (2025.10.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3,>=2.3->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3,>=2.3->bitsandbytes) (3.0.3)\n",
            "Downloading bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl (59.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.48.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas==2.2.2  sentence-transformers\n",
        "!pip install --upgrade --force-reinstall numpy==1.26.4\n",
        "!pip install chromadb==1.0.20\n",
        "!pip install rank_bm25==0.2.2\n",
        "!pip -q install flask flask-cors pyngrok waitress rank_bm25 sentence_transformers chromadb transformers huggingface_hub\n",
        "!pip install -U bitsandbytes accelerate \"transformers>=4.44\" peft\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnRN_PWtuWHm",
        "outputId": "c0c35899-4af3-4fbb-e1b4-61f49b986837"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "t-yHkLUsuwmP"
      },
      "outputs": [],
      "source": [
        "import os, re, json, csv, time, threading\n",
        "from typing import List, Dict, Any, Tuple\n",
        "from collections import defaultdict\n",
        "from datetime import datetime, timezone\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "from rank_bm25 import BM25Okapi\n",
        "from sentence_transformers import CrossEncoder\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from huggingface_hub import login\n",
        "\n",
        "from chromadb import PersistentClient\n",
        "from chromadb.config import Settings\n",
        "from chromadb.utils import embedding_functions\n",
        "\n",
        "from flask import Flask, request, jsonify\n",
        "from flask_cors import CORS\n",
        "from pyngrok import ngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jorc_Somux-J"
      },
      "outputs": [],
      "source": [
        "NOTEBOOK_API_KEY = os.getenv(\"NOTEBOOK_API_KEY\", \"dev-notebook\")  # must match backend's NOTEBOOK_API_KEY\n",
        "\n",
        "CHROMA_PATH     = \"/content/drive/MyDrive/chroma\"\n",
        "COLLECTION_NAME = \"actSectionsV2\"\n",
        "EMBED_MODEL     = \"intfloat/e5-base-v2\"\n",
        "\n",
        "TOPK_DENSE_WIDE   = 300\n",
        "TOPK_BM25_WIDE    = 300\n",
        "TOPK_CE_RERANK    = 400\n",
        "TOPK_FINAL        = 6\n",
        "\n",
        "# Early-fusion weights\n",
        "W_BM25_DOC   = 0.35\n",
        "W_BM25_HEAD  = 0.35\n",
        "W_DENSE      = 0.30\n",
        "\n",
        "# Final fusion\n",
        "ALPHA_FUSION = 0.80\n",
        "\n",
        "HEADING_PRIOR_POS = 0.05\n",
        "HEADING_PRIOR_NEG = -0.05\n",
        "\n",
        "# Soft Act prior weight added per candidate based on fused act mass\n",
        "ACT_PRIOR_BETA = 0.05\n",
        "\n",
        "# Act-gating\n",
        "ACT_GATING_K   = 3\n",
        "ACT_CONF_MIN   = 0.55\n",
        "\n",
        "DEAD_HEAD_RE  = re.compile(r\"\\b(spent|repealed|revoked|deleted)\\b|\\[\\s*spent\\s*\\]\", re.I)\n",
        "INTERP_RE     = re.compile(r\"\\binterpretation\\b\", re.I)\n",
        "\n",
        "SALIENT_TERMS = [\n",
        "    \"equality\",\"non-discrimination\",\"discrimination\",\"privacy\",\"consent\",\n",
        "    \"detention\",\"expression\",\"housing\",\"health\",\"education\",\"water\",\n",
        "    \"termination\",\"unfair termination\",\"redundancy\",\"dismissal\",\n",
        "    \"children\",\"bail\",\"arrest\",\"data\",\"lawful processing\",\"principles of data protection\"\n",
        "]\n",
        "\n",
        "\n",
        "client = PersistentClient(path=CHROMA_PATH, settings=Settings(allow_reset=True))\n",
        "print(\"Existing collections:\", [c.name for c in client.list_collections()])\n",
        "coll = client.get_collection(COLLECTION_NAME)\n",
        "print(f\"Loaded collection '{COLLECTION_NAME}' with {coll.count()} documents\")\n",
        "\n",
        "ef = embedding_functions.SentenceTransformerEmbeddingFunction(model_name=EMBED_MODEL)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efc4qFSUu9PG"
      },
      "outputs": [],
      "source": [
        "def load_corpus_df(chroma_coll) -> pd.DataFrame:\n",
        "    limit = 5000\n",
        "    offset = 0\n",
        "    all_ids, all_docs, all_metas = [], [], []\n",
        "    while True:\n",
        "        batch = chroma_coll.get(limit=limit, offset=offset, include=[\"documents\",\"metadatas\"])\n",
        "        ids = batch.get(\"ids\", [])\n",
        "        if not ids:\n",
        "            break\n",
        "        all_ids.extend(ids)\n",
        "        all_docs.extend(batch.get(\"documents\", []))\n",
        "        all_metas.extend(batch.get(\"metadatas\", []))\n",
        "        offset += len(ids)\n",
        "        if len(ids) < limit:\n",
        "            break\n",
        "\n",
        "    rows = []\n",
        "    for _id, doc, meta in zip(all_ids, all_docs, all_metas):\n",
        "        meta = meta or {}\n",
        "        act  = meta.get(\"act\") or meta.get(\"Act\") or \"\"\n",
        "        heading = meta.get(\"section_title\") or meta.get(\"heading\") or meta.get(\"title\") or \"\"\n",
        "        section_num = str(meta.get(\"section\") or meta.get(\"section_num\") or \"\").strip()\n",
        "        rows.append({\n",
        "            \"id\": _id,\n",
        "            \"doc\": doc or \"\",\n",
        "            \"heading\": heading or \"\",\n",
        "            \"act\": act,\n",
        "            \"section_num\": section_num\n",
        "        })\n",
        "    df = pd.DataFrame(rows)\n",
        "    df[\"heading\"] = df[\"heading\"].fillna(\"\")\n",
        "    df[\"section_num\"] = df[\"section_num\"].fillna(\"\")\n",
        "    return df\n",
        "\n",
        "corpus_df = load_corpus_df(coll)\n",
        "assert not corpus_df.empty, \"corpus_df is empty — check collection contents.\"\n",
        "print(\"corpus_df shape:\", corpus_df.shape)\n",
        "id2 = corpus_df.set_index(\"id\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwfwV4eCvAg7"
      },
      "outputs": [],
      "source": [
        "corpus_df = load_corpus_df(coll)\n",
        "assert not corpus_df.empty, \"corpus_df is empty — check collection contents.\"\n",
        "print(\"corpus_df shape:\", corpus_df.shape)\n",
        "id2 = corpus_df.set_index(\"id\")\n",
        "\n",
        "def _tok(t: str):\n",
        "    return [x for x in re.split(r\"\\W+\", (t or \"\").lower()) if x]\n",
        "\n",
        "bm25_doc  = BM25Okapi([_tok(d) for d in corpus_df[\"doc\"].tolist()])\n",
        "bm25_head = BM25Okapi([_tok(h) for h in corpus_df[\"heading\"].fillna(\"\").tolist()])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TdDmwSbpvC-S"
      },
      "outputs": [],
      "source": [
        "def _minmax(xs):\n",
        "    if not xs: return []\n",
        "    mn, mx = float(min(xs)), float(max(xs))\n",
        "    if mx <= mn: return [0.0]*len(xs)\n",
        "    return [(x-mn)/(mx-mn) for x in xs]\n",
        "\n",
        "# ----------------------------\n",
        "# Dense + BM25 candidate functions\n",
        "# ----------------------------\n",
        "def _dense_candidates(q, n):\n",
        "    q_embed = ef([f\"query: {q}\"])\n",
        "    res = coll.query(query_embeddings=q_embed, n_results=n, include=[\"distances\"])\n",
        "    return res[\"ids\"][0], res[\"distances\"][0]  # distances lower=better\n",
        "\n",
        "def _bm25_doc_candidates(q, n):\n",
        "    scores = bm25_doc.get_scores(_tok(q))\n",
        "    idx = np.argsort(scores)[::-1][:n]\n",
        "    return [corpus_df.loc[i,\"id\"] for i in idx], [float(scores[i]) for i in idx]\n",
        "\n",
        "def _bm25_head_candidates(q, n):\n",
        "    scores = bm25_head.get_scores(_tok(q))\n",
        "    idx = np.argsort(scores)[::-1][:n]\n",
        "    return [corpus_df.loc[i,\"id\"] for i in idx], [float(scores[i]) for i in idx]\n",
        "\n",
        "def _dense_to_sim(dists):\n",
        "    return _minmax([-d for d in dists])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zjvpxrC1vGlf"
      },
      "outputs": [],
      "source": [
        "\n",
        "def _act_topk_share_and_map(ids, scores, k=3):\n",
        "    mass, total = defaultdict(float), 0.0\n",
        "    for _id, sc in zip(ids, scores):\n",
        "        if _id in id2.index:\n",
        "            a = str(id2.loc[_id, \"act\"] or \"\")\n",
        "            mass[a] += sc; total += sc\n",
        "    ranked = sorted(mass.items(), key=lambda kv: kv[1], reverse=True)\n",
        "    share  = (ranked[0][1]/total) if (ranked and total>0) else 0.0\n",
        "    topk   = [a for a,_ in ranked[:k] if a]\n",
        "    act_share = {a: (v/total if total>0 else 0.0) for a, v in mass.items()}\n",
        "    return topk, share, act_share"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZSVXP_bzvIa5"
      },
      "outputs": [],
      "source": [
        "def _heading_prior(heading, q):\n",
        "    h, ql = (heading or \"\").lower(), (q or \"\").lower()\n",
        "    if any(t in h for t in SALIENT_TERMS) and any(t in ql for t in SALIENT_TERMS):\n",
        "        return HEADING_PRIOR_POS\n",
        "    if DEAD_HEAD_RE.search(h): return HEADING_PRIOR_NEG\n",
        "    if INTERP_RE.search(h):    return -0.03\n",
        "    return 0.0\n",
        "\n",
        "def _overlap_prior(heading, q):\n",
        "    ht, qt = set(_tok(heading)), set(_tok(q))\n",
        "    if not ht or not qt: return 0.0\n",
        "    jacc = len(ht & qt) / max(1, len(ht | qt))\n",
        "    bonus = min(0.05, 0.30 * jacc)\n",
        "    qtokens = _tok(q)\n",
        "    phrases = [\" \".join(p) for p in zip(qtokens, qtokens[1:])]\n",
        "    if any(p and p in (heading or \"\").lower() for p in phrases):\n",
        "        bonus += 0.02\n",
        "    return min(bonus, 0.07)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VeLv_33tvKpM"
      },
      "outputs": [],
      "source": [
        "def _section_num_bonus(q, sec_num):\n",
        "    if not sec_num: return 0.0\n",
        "    q_nums = re.findall(r\"\\d+\", (q or \"\"))\n",
        "    return 0.03 if sec_num in q_nums else 0.0\n",
        "\n",
        "def _fmt_section(sec_num, head):\n",
        "    sec_num = (sec_num or \"\").strip()\n",
        "    head    = (head or \"\").strip()\n",
        "    return f\"{sec_num} - {head}\" if sec_num and head else (sec_num or head or \"\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PRe14EnvMg3"
      },
      "source": [
        "### RERANKER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xC3i5rPlvNyx"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "ce = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\", max_length=512, device=device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "waOb3FXLvPwj"
      },
      "outputs": [],
      "source": [
        "def retrieve_top6_for_question_T6(q: str) -> Dict[str, Any]:\n",
        "    # 1) Wide pools\n",
        "    d_ids, d_dists = _dense_candidates(q, TOPK_DENSE_WIDE)\n",
        "    bd_ids, bd_scs = _bm25_doc_candidates(q, TOPK_BM25_WIDE)\n",
        "    bh_ids, bh_scs = _bm25_head_candidates(q, TOPK_BM25_WIDE)\n",
        "\n",
        "    # 2) Early fusion\n",
        "    d_norm  = _dense_to_sim(d_dists)\n",
        "    bd_norm = _minmax(bd_scs)\n",
        "    bh_norm = _minmax(bh_scs)\n",
        "\n",
        "    fuse = defaultdict(float)\n",
        "    for i, _id in enumerate(d_ids):  fuse[_id]  += W_DENSE     * d_norm[i]\n",
        "    for i, _id in enumerate(bd_ids): fuse[_id]  += W_BM25_DOC  * bd_norm[i]\n",
        "    for i, _id in enumerate(bh_ids): fuse[_id]  += W_BM25_HEAD * bh_norm[i]\n",
        "\n",
        "    cand_ids    = sorted(fuse.keys(), key=lambda k: fuse[k], reverse=True)\n",
        "    cand_scores = [fuse[_id] for _id in cand_ids]\n",
        "\n",
        "    # 3) Act-gating + soft act prior map\n",
        "    top_acts, share, act_share = _act_topk_share_and_map(cand_ids, cand_scores, k=ACT_GATING_K)\n",
        "    if share >= ACT_CONF_MIN and top_acts:\n",
        "        gated = []\n",
        "        for _id in cand_ids:\n",
        "            if _id in id2.index and id2.loc[_id, \"act\"] in top_acts:\n",
        "                gated.append(_id)\n",
        "            if len(gated) >= TOPK_CE_RERANK: break\n",
        "    else:\n",
        "        gated = cand_ids[:TOPK_CE_RERANK]\n",
        "\n",
        "    # 4) CE rerank\n",
        "    qdoc = [(q, id2.loc[_id, \"doc\"]) for _id in gated]\n",
        "    ce_scores = ce.predict(qdoc, batch_size=32, show_progress_bar=False).tolist()\n",
        "    ce_norm   = _minmax(ce_scores)\n",
        "\n",
        "    # dense sims for same gated set\n",
        "    d_map       = {i:d for i,d in zip(d_ids, d_dists)}\n",
        "    dense_sims  = [(-d_map[_id] if _id in d_map else float(\"-inf\")) for _id in gated]\n",
        "    dense_norm2 = _minmax(dense_sims)\n",
        "\n",
        "    # 5) Final fusion + priors\n",
        "    finals = []\n",
        "    for i, _id in enumerate(gated):\n",
        "        row    = id2.loc[_id]\n",
        "        head   = row[\"heading\"]\n",
        "        secnum = str(row[\"section_num\"] or \"\")\n",
        "        act    = str(row[\"act\"] or \"\")\n",
        "\n",
        "        score = (\n",
        "            ALPHA_FUSION * ce_norm[i] +\n",
        "            (1.0 - ALPHA_FUSION) * dense_norm2[i] +\n",
        "            _heading_prior(head, q) +\n",
        "            _overlap_prior(head, q) +\n",
        "            ACT_PRIOR_BETA * float(act_share.get(act, 0.0)) +\n",
        "            _section_num_bonus(q, secnum)\n",
        "        )\n",
        "        finals.append((_id, score))\n",
        "\n",
        "    finals_sorted = sorted(finals, key=lambda t: t[1], reverse=True)\n",
        "\n",
        "    # 6) De-dup by section number (best per section)\n",
        "    seen_secs, top_ids = set(), []\n",
        "    for _id, _sc in finals_sorted:\n",
        "        s = str(id2.loc[_id, \"section_num\"] or \"\")\n",
        "        if s and s in seen_secs:\n",
        "            continue\n",
        "        seen_secs.add(s)\n",
        "        top_ids.append(_id)\n",
        "        if len(top_ids) >= TOPK_FINAL: break\n",
        "    if len(top_ids) < TOPK_FINAL:\n",
        "        for _id, _ in finals_sorted:\n",
        "            if _id not in top_ids:\n",
        "                top_ids.append(_id)\n",
        "            if len(top_ids) >= TOPK_FINAL: break\n",
        "\n",
        "    sub = id2.loc[top_ids].reset_index()\n",
        "    return {\n",
        "        \"Top6_IDs\": top_ids,\n",
        "        \"Top6_Sections_fmt\": [_fmt_section(s, h) for s,h in zip(sub[\"section_num\"], sub[\"heading\"])],\n",
        "        \"Top6_Answers\": sub[\"doc\"].tolist(),\n",
        "        \"Top6_Acts\": sub[\"act\"].tolist(),\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ANSI7uPMvTt6"
      },
      "outputs": [],
      "source": [
        "def _build_context_from_bundle(bundle: Dict[str, Any]) -> str:\n",
        "    ctx = []\n",
        "    for i, (sec, act, doc) in enumerate(zip(bundle[\"Top6_Sections_fmt\"], bundle[\"Top6_Acts\"], bundle[\"Top6_Answers\"]), start=1):\n",
        "        ctx.append(f\"[{i}] {act} - {sec}\\n{doc.strip()}\")\n",
        "    return \"\\n\\n\".join(ctx)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "My_IS9VwvXxb"
      },
      "source": [
        "### LOADING QWEN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5x84rwFfvZqP"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    login()\n",
        "except Exception:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HEKDO-Dxvchu"
      },
      "outputs": [],
      "source": [
        "MODEL_NAME = \"Qwen/Qwen3-8B\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\",\n",
        "    load_in_4bit=True\n",
        ")\n",
        "print(\"Qwen model loaded successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b945ee608c52"
      },
      "source": [
        "### MODEL WARM-UP\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c618acf5b447"
      },
      "outputs": [],
      "source": [
        "# Warm up embedding and reranker to avoid first-request latency\n",
        "_warmup_q = \"Warm-up query about employment law\"\n",
        "_warmup_doc = \"This is placeholder legal text for warm-up purposes only.\"\n",
        "_ = ef([f\"query: {_warmup_q}\"])\n",
        "with torch.inference_mode():\n",
        "    _ = ce.predict([(_warmup_q, _warmup_doc)], batch_size=1, show_progress_bar=False)\n",
        "print(\"Retrieval models warmed up.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36c5a1590da4"
      },
      "outputs": [],
      "source": [
        "# Warm up generator to cache weights on device\n",
        "warmup_messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are Uhaki, an AI legal assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Provide a short legal summary for warm-up.\"}\n",
        "]\n",
        "warmup_text = tokenizer.apply_chat_template(\n",
        "    warmup_messages,\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True\n",
        ")\n",
        "warmup_inputs = tokenizer(warmup_text, return_tensors=\"pt\").to(model.device)\n",
        "with torch.no_grad():\n",
        "    _ = model.generate(\n",
        "        **warmup_inputs,\n",
        "        max_new_tokens=32,\n",
        "        temperature=0.7,\n",
        "        top_p=0.9\n",
        "    )\n",
        "print(\"Generation model warmed up.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UoNqynxMvf5I"
      },
      "outputs": [],
      "source": [
        "def generate_uhaki_answer(query: str, bundle: Dict[str, Any], enable_thinking: bool = False) -> str:\n",
        "    context = _build_context_from_bundle(bundle)\n",
        "    system_prompt = (\n",
        "        \"You are Uhaki, an AI legal assistant for Kenyan law. \"\n",
        "        \"Answer the user's question using only the legal information provided in the context below. \"\n",
        "        \"Provide a concise but complete legal summary. \"\n",
        "        \"Cite Acts and sections in parentheses (e.g., Employment Act s.44). \"\n",
        "        \"If the answer is not in the context, say so.\"\n",
        "    )\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": f\"Context:\\n{context}\\n\\nQuestion: {query}\"}\n",
        "    ]\n",
        "    text = tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        tokenize=False,\n",
        "        add_generation_prompt=True,\n",
        "        enable_thinking=enable_thinking\n",
        "    )\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\").to(model.device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=512,\n",
        "            temperature=0.2,\n",
        "            top_p=0.9\n",
        "        )\n",
        "    decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    cleaned = re.split(r\"(?:Question:.*?\\n|assistant\\n)\", decoded, flags=re.IGNORECASE)[-1].strip()\n",
        "    cleaned = re.sub(r\"<think>.*?</think>\", \"\", cleaned, flags=re.DOTALL | re.IGNORECASE)\n",
        "    cleaned = re.sub(r\"\\s+\", \" \", cleaned).strip()\n",
        "    return cleaned"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoJ7FY64v5b9"
      },
      "source": [
        "### FLASK APP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujgy4tLcv7WX"
      },
      "outputs": [],
      "source": [
        "def generate_uhaki_answer(query: str, bundle: Dict[str, Any], enable_thinking: bool = False) -> str:\n",
        "    context = _build_context_from_bundle(bundle)\n",
        "    system_prompt = (\n",
        "        \"You are Uhaki, an AI legal assistant for Kenyan law. \"\n",
        "        \"Answer the user's question using only the legal information provided in the context below. \"\n",
        "        \"Provide a concise but complete legal summary. \"\n",
        "        \"Cite Acts and sections in parentheses (e.g., Employment Act s.44). \"\n",
        "        \"If the answer is not in the context, say so.\"\n",
        "    )\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": f\"Context:\\n{context}\\n\\nQuestion: {query}\"}\n",
        "    ]\n",
        "    text = tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        tokenize=False,\n",
        "        add_generation_prompt=True,\n",
        "        enable_thinking=enable_thinking\n",
        "    )\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\").to(model.device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=512,\n",
        "            temperature=0.2,\n",
        "            top_p=0.9\n",
        "        )\n",
        "    decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    cleaned = re.split(r\"(?:Question:.*?\\n|assistant\\n)\", decoded, flags=re.IGNORECASE)[-1].strip()\n",
        "    cleaned = re.sub(r\"<think>.*?</think>\", \"\", cleaned, flags=re.DOTALL | re.IGNORECASE)\n",
        "    cleaned = re.sub(r\"\\s+\", \" \", cleaned).strip()\n",
        "    return cleaned"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AP5--lWzwAKf"
      },
      "source": [
        "### FLASK APP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cvA7H8o1v9GK"
      },
      "outputs": [],
      "source": [
        "app = Flask(__name__)\n",
        "CORS(app)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23eJ5-DCwB6l"
      },
      "outputs": [],
      "source": [
        "@app.get(\"/health\")\n",
        "def health():\n",
        "    return jsonify({\n",
        "        \"ok\": True,\n",
        "        \"collection\": COLLECTION_NAME,\n",
        "        \"docs\": int(coll.count()),\n",
        "        \"embed_model\": EMBED_MODEL,\n",
        "        \"ce_model\": \"cross-encoder/ms-marco-MiniLM-L-6-v2\",\n",
        "        \"gen_model\": MODEL_NAME\n",
        "    })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1aLQtnHCwECk"
      },
      "outputs": [],
      "source": [
        "@app.post(\"/generate\")\n",
        "def generate():\n",
        "    # Simple auth\n",
        "    if request.headers.get(\"X-API-Key\") != NOTEBOOK_API_KEY:\n",
        "        return jsonify({\"error\": \"Unauthorized\"}), 401\n",
        "\n",
        "    data = request.get_json(force=True) or {}\n",
        "    query = (data.get(\"query\") or \"\").strip()\n",
        "    top_k_return   = int(data.get(\"top_k_return\", TOPK_FINAL))\n",
        "    # Note: our pipeline already uses wide pools internally; top_k_retrieve is ignored.\n",
        "\n",
        "    if not query:\n",
        "        return jsonify({\"error\": \"No query provided\"}), 400\n",
        "\n",
        "    # Retrieval\n",
        "    bundle = retrieve_top6_for_question_T6(query)\n",
        "    # If caller asked fewer than 6 back\n",
        "    if top_k_return < TOPK_FINAL:\n",
        "        for k in [\"Top6_IDs\", \"Top6_Sections_fmt\", \"Top6_Answers\", \"Top6_Acts\"]:\n",
        "            bundle[k] = bundle[k][:top_k_return]\n",
        "\n",
        "    # Generation\n",
        "    answer = generate_uhaki_answer(query, bundle)\n",
        "\n",
        "    # Response\n",
        "    acts_sections = [\n",
        "        {\"act\": act, \"section\": sec}\n",
        "        for act, sec in zip(bundle[\"Top6_Acts\"], bundle[\"Top6_Sections_fmt\"])\n",
        "    ]\n",
        "    return jsonify({\n",
        "        \"ok\": True,\n",
        "        \"query\": query,\n",
        "        \"answer\": answer,\n",
        "        \"top6\": acts_sections,\n",
        "        \"raw\": {\n",
        "            \"ids\": bundle[\"Top6_IDs\"],\n",
        "            \"sections_fmt\": bundle[\"Top6_Sections_fmt\"],\n",
        "            \"acts\": bundle[\"Top6_Acts\"]\n",
        "        }\n",
        "    })\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N284BcaZwOdB"
      },
      "outputs": [],
      "source": [
        "NGROK_TOKEN = \"YOUR_NGROK_AUTHTOKEN_HERE\"  # put your token here\n",
        "!ngrok config add-authtoken $NGROK_TOKEN\n",
        "\n",
        "public_url = ngrok.connect(addr=5001, proto=\"http\")\n",
        "print(\"Notebook public URL:\", public_url)\n",
        "os.environ[\"PUBLIC_NOTEBOOK_URL\"] = str(public_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9G2u_-DwVv5"
      },
      "outputs": [],
      "source": [
        "def run_server():\n",
        "    from waitress import serve\n",
        "    serve(app, host=\"0.0.0.0\", port=5001, threads=8)\n",
        "\n",
        "threading.Thread(target=run_server, daemon=True).start()\n",
        "time.sleep(2)\n",
        "print(\"Notebook server ready at:\", public_url, \" — endpoint: /generate\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}